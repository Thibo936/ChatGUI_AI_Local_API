# ChatGUI\_AI\_Local\_API

> **English üá¨üáß | Fran√ßais üá´üá∑**
> A simple bilingual README for a simple local AI chat GUI.

---

## English üá¨üáß

### Overview

**ChatGUI\_AI\_Local\_API** is a lightweight desktop application written in Python‚ÄØ+‚ÄØPySide6 that lets you chat with:

* **Local models** served by **[Ollama](https://ollama.com/)** (`localhost:11434`)
* **OpenAI models** (when `OPENAI_API_KEY` is defined)

It ships with a clean GUI that supports multiple conversations, model favourites, visible chain‚Äëof‚Äëthought, and real‚Äëtime resource usage.

### Key features

* Multi‚Äëconversation sidebar with auto‚Äësave to `%APPDATA%/OllamaChats`
* Toggle assistant chain‚Äëof‚Äëthought (`<think>‚Ä¶</think>`) with a single click
* Model favourites ‚≠ê and instant switch
* Token statistics (total & tok/s) + CPU/RAM monitor
* Automatic checks for missing Python deps & VC++ runtime on Windows

### Prerequisites

| Requirement      | Notes                                                        |
| ---------------- | ------------------------------------------------------------ |
| Python **3.10+** | Windows / macOS / Linux                                      |
| **Ollama**       | Needed only for local models ‚Äì must run on `localhost:11434` |
| `OPENAI_API_KEY` | Optional ‚Äì enables OpenAI models                             |

### Installation

```bash
# 1. Clone
$ git clone https://github.com/your‚Äëname/ChatGUI_AI_Local_API.git
$ cd ChatGUI_AI_Local_API

# 2. Create venv (recommended)
$ python -m venv .venv
$ source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3. Install deps
$ pip install -r requirements.txt
```

### Running

```bash
python ollama_chat_gui3.py
```

On first launch the app proposes to install missing Python packages, VC++ redistributable, or start **Ollama** if it is not detected.

### Environment variables

* `OPENAI_API_KEY` ‚Äì OpenAI key (optional)
* `LOCALAPPDATA`  ‚Äì Overrides default data directory on Windows

### File structure

```
ollama_chat_gui3.py        # Main application
requirements.txt          # Dependencies
%APPDATA%/OllamaChats/    # Auto‚Äësaved chats & settings
  ‚îú‚îÄ‚îÄ model_favorites.json
  ‚îî‚îÄ‚îÄ <uuid>.json         # One file per conversation
```

### Packaging (Windows)

```bash
pip install pyinstaller
pyinstaller --onefile --noconsole ollama_chat_gui3.py
```

### Contributing

Pull requests and issues are welcome!

### License

MIT

---

## Fran√ßais üá´üá∑

### Aper√ßu

**ChatGUI\_AI\_Local\_API** est une application de bureau l√©g√®re (Python‚ÄØ+‚ÄØPySide6) qui permet de discuter‚ÄØ:

* avec des **mod√®les locaux** servis par **[Ollama](https://ollama.com/)** (`localhost:11434`)
* avec des **mod√®les OpenAI** (si la variable `OPENAI_API_KEY` est d√©finie)

Elle propose une interface soign√©e, la gestion de plusieurs conversations, des mod√®les favoris, l‚Äôaffichage des pens√©es de l‚ÄôIA et la surveillance des ressources syst√®me.

### Fonctionnalit√©s cl√©s

* Barre lat√©rale multi‚Äëconversations avec sauvegarde automatique dans `%APPDATA%/OllamaChats`
* Affichage/masquage des pens√©es de l‚ÄôIA (`<think>‚Ä¶</think>`) en un clic
* Favoris de mod√®les ‚≠ê et changement instantan√©
* Statistiques de tokens (total & tok/s) + moniteur CPU/RAM en temps r√©el
* V√©rifications automatiques des d√©pendances Python et du runtime VC++ sous Windows

### Pr√©requis

| Pr√©‚Äërequis       | Notes                                                                              |
| ---------------- | ---------------------------------------------------------------------------------- |
| Python **3.10+** | Windows / macOS / Linux                                                            |
| **Ollama**       | N√©cessaire uniquement pour les mod√®les locaux ‚Äì doit tourner sur `localhost:11434` |
| `OPENAI_API_KEY` | Optionnel ‚Äì active les mod√®les OpenAI                                              |

### Installation

```bash
# 1. Cloner le d√©p√¥t
$ git clone https://github.com/votre‚Äëpseudo/ChatGUI_AI_Local_API.git
$ cd ChatGUI_AI_Local_API

# 2. Cr√©er un virtualenv (recommand√©)
$ python -m venv .venv
$ source .venv/bin/activate   # Windows : .venv\Scripts\activate

# 3. Installer les d√©pendances
$ pip install -r requirements.txt
```

### Lancement

```bash
python ollama_chat_gui3.py
```

Au premier d√©marrage, l‚Äôapplication propose d‚Äôinstaller les paquets Python manquants, le runtime VC++ ou de lancer **Ollama** s‚Äôil n‚Äôest pas d√©tect√©.

### Variables d‚Äôenvironnement

* `OPENAI_API_KEY` ‚Äì Cl√© OpenAI (optionnel)
* `LOCALAPPDATA`  ‚Äì Red√©finit le r√©pertoire de donn√©es sous Windows

### Arborescence

```
ollama_chat_gui3.py        # Application principale
requirements.txt          # D√©pendances
%APPDATA%/OllamaChats/    # Conversations et param√®tres sauvegard√©s
  ‚îú‚îÄ‚îÄ model_favorites.json
  ‚îî‚îÄ‚îÄ <uuid>.json         # Une conversation par fichier
```

### Cr√©ation d‚Äôun ex√©cutable Windows

```bash
pip install pyinstaller
pyinstaller --onefile --noconsole ollama_chat_gui3.py
```

### Contribuer

Les pull requests et issues sont les bienvenus‚ÄØ!

### Licence

MIT
