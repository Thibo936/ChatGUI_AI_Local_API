# ChatGUI_AI_Local_API

> **English üá¨üáß | Fran√ßais üá´üá∑**
> Bilingual README for a local AI chat GUI with file attachments and vision support.

---

## English üá¨üáß

### Overview

**ChatGUI_AI_Local_API** is a lightweight desktop application (Python + PySide6) to chat with:

* **Local models** served by **[Ollama](https://ollama.com/)** (`localhost:11434`)
* **OpenAI models** (if `OPENAI_API_KEY` is set)

It features a clean GUI, multi-conversation, model favourites, visible chain-of-thought, file attachments, and real-time resource usage.

### Key features

* **Multi-conversation** sidebar with auto-save to `%APPDATA%/OllamaChats`
* **File attachments** support:
  - **Images** (PNG, JPG, WEBP, etc.) with vision model support
  - **PDFs** with automatic text extraction
  - **Text files** (code, documents, etc.)
  - Drag & drop functionality
* **Vision models** support for image analysis (Ollama: LLaVA, Gemma3, Qwen2.5VL, Moondream | OpenAI: GPT-4o, GPT-4.1, etc.)
* Toggle assistant **chain-of-thought** (`<think>‚Ä¶</think>`) with a single click
* **Model management**:
  - Favourites ‚≠ê with priority display
  - Visibility settings to hide/show specific models
  - Automatic detection of vision capabilities
* **Token statistics** (total & tok/s) + CPU/RAM monitor
* **Code blocks** with syntax highlighting and copy functionality
* Automatic checks for missing Python dependencies & VC++ runtime on Windows
* Automatic detection and launch of Ollama server if not running

### Prerequisites

| Requirement      | Notes                                                        |
| ---------------- | ------------------------------------------------------------ |
| Python **3.10+** | Windows / macOS / Linux                                      |
| **Ollama**       | Needed only for local models ‚Äì must run on `localhost:11434` |
| `OPENAI_API_KEY` | Optional ‚Äì enables OpenAI models                             |

### Required dependencies

The application uses these packages for file processing:

* **Pillow** ‚Äì Image processing, resizing, and format conversion
* **PyPDF2** ‚Äì PDF text extraction for document analysis
* **pytesseract** ‚Äì OCR (Optical Character Recognition) for extracting text from images when vision models aren't available

### Installation

```bash
# 1. Clone
$ git clone https://github.com/your‚Äëname/ChatGUI_AI_Local_API.git
$ cd ChatGUI_AI_Local_API

# 2. Create venv (recommended)
$ python -m venv .venv
$ source .venv/bin/activate   # Windows: .venv\Scripts\activate

# 3. Install dependencies
$ pip install -r requirements.txt

# 4. For OCR functionality, install Tesseract OCR on your system:
# Windows: Download from https://github.com/UB-Mannheim/tesseract/wiki
# macOS: brew install tesseract
# Linux: sudo apt-get install tesseract-ocr
```

### Running

```bash
python main.py
```

On first launch, the app will propose to install missing Python packages, VC++ redistributable, or start **Ollama** if not detected.

### Supported models

**Ollama models with vision support:**
- LLaVA (all variants)
- Gemma3 (vision models)
- Qwen2.5VL
- Moondream
- Llama 3.2 Vision
- BakLLaVA
- Granite 3.2 Vision
- LLaVA-Phi3

**OpenAI models with vision support:**
- GPT-4o and variants
- GPT-4.1 series
- O1, O3, O4 series

### Environment variables

* `OPENAI_API_KEY` ‚Äì OpenAI key (optional)
* `LOCALAPPDATA`  ‚Äì Overrides default data directory on Windows

### File structure

```
main.py                  # Main application
config.py                # Configuration
ollama_client.py         # Ollama API client
chat_window.py           # Main GUI window
models.py                # Message & ModelCaps dataclasses
utils.py                 # Utilities (logging, checks, etc.)
file_utils.py            # File processing utilities (images, PDFs, OCR)
requirements.txt         # Dependencies
%APPDATA%/OllamaChats/   # Auto-saved chats & settings
  ‚îú‚îÄ‚îÄ model_favorites.json
  ‚îú‚îÄ‚îÄ model_visibility.json
  ‚îî‚îÄ‚îÄ <uuid>.json        # One file per conversation
```

### Usage

1. **Start a conversation**: Click "‚ûï Nouvelle conversation"
2. **Attach files**: 
   - Click the üìé button or drag & drop files
   - Supported: Images (analyzed by vision models), PDFs (text extracted), text files
3. **Switch models**: Use the dropdown and ‚öôÔ∏è button to manage visibility
4. **View thinking**: Click ‚ñ∂ arrows to expand AI reasoning
5. **Copy code**: Click üìÑ button on code blocks

### Packaging (Windows)

```bash
pip install pyinstaller
pyinstaller --onefile --noconsole main.py
```

### Contributing

Pull requests and issues are welcome!

### License

MIT

---

## Fran√ßais üá´üá∑

### Aper√ßu

**ChatGUI_AI_Local_API** est une application de bureau l√©g√®re (Python + PySide6) qui permet de discuter :

* avec des **mod√®les locaux** servis par **[Ollama](https://ollama.com/)** (`localhost:11434`)
* avec des **mod√®les OpenAI** (si la variable `OPENAI_API_KEY` est d√©finie)

Elle propose une interface soign√©e, la gestion de plusieurs conversations, des mod√®les favoris, l'affichage des pens√©es de l'IA, la prise en charge de fichiers joints et la surveillance des ressources syst√®me.

### Fonctionnalit√©s cl√©s

* **Multi-conversations** avec sauvegarde automatique dans `%APPDATA%/OllamaChats`
* **Pi√®ces jointes** :
  - **Images** (PNG, JPG, WEBP, etc.) avec support des mod√®les de vision
  - **PDFs** avec extraction automatique de texte
  - **Fichiers texte** (code, documents, etc.)
  - Fonctionnalit√© glisser-d√©poser
* **Mod√®les de vision** pour l'analyse d'images (Ollama : LLaVA, Gemma3, Qwen2.5VL, Moondream | OpenAI : GPT-4o, GPT-4.1, etc.)
* Affichage/masquage des **pens√©es de l'IA** (`<think>‚Ä¶</think>`) en un clic
* **Gestion des mod√®les** :
  - Favoris ‚≠ê avec affichage prioritaire
  - Param√®tres de visibilit√© pour masquer/afficher des mod√®les sp√©cifiques
  - D√©tection automatique des capacit√©s de vision
* **Statistiques de tokens** (total & tok/s) + moniteur CPU/RAM en temps r√©el
* **Blocs de code** avec coloration syntaxique et fonction de copie
* V√©rification automatique des d√©pendances Python et du runtime VC++ sous Windows
* D√©tection et lancement automatique du serveur Ollama si n√©cessaire

### Pr√©requis

| Pr√©-requis       | Notes                                                                              |
| ---------------- | ---------------------------------------------------------------------------------- |
| Python **3.10+** | Windows / macOS / Linux                                                            |
| **Ollama**       | N√©cessaire uniquement pour les mod√®les locaux ‚Äì doit tourner sur `localhost:11434` |
| `OPENAI_API_KEY` | Optionnel ‚Äì active les mod√®les OpenAI                                              |

### D√©pendances requises

L'application utilise ces packages pour le traitement de fichiers :

* **Pillow** ‚Äì Traitement d'images, redimensionnement et conversion de formats
* **PyPDF2** ‚Äì Extraction de texte des PDFs pour l'analyse de documents
* **pytesseract** ‚Äì OCR (Reconnaissance Optique de Caract√®res) pour extraire le texte des images quand les mod√®les de vision ne sont pas disponibles

### Installation

```bash
# 1. Cloner le d√©p√¥t
$ git clone https://github.com/votre‚Äëpseudo/ChatGUI_AI_Local_API.git
$ cd ChatGUI_AI_Local_API

# 2. Cr√©er un virtualenv (recommand√©)
$ python -m venv .venv
$ source .venv/bin/activate   # Windows : .venv\Scripts\activate

# 3. Installer les d√©pendances
$ pip install -r requirements.txt

# 4. Pour la fonctionnalit√© OCR, installer Tesseract OCR sur votre syst√®me :
# Windows : T√©l√©charger depuis https://github.com/UB-Mannheim/tesseract/wiki
# macOS : brew install tesseract
# Linux : sudo apt-get install tesseract-ocr
```

### Lancement

```bash
python main.py
```

Au premier d√©marrage, l'application propose d'installer les paquets Python manquants, le runtime VC++ ou de lancer **Ollama** s'il n'est pas d√©tect√©.

### Mod√®les support√©s

**Mod√®les Ollama avec support vision :**
- LLaVA (toutes variantes)
- Gemma3 (mod√®les vision)
- Qwen2.5VL
- Moondream
- Llama 3.2 Vision
- BakLLaVA
- Granite 3.2 Vision
- LLaVA-Phi3

**Mod√®les OpenAI avec support vision :**
- GPT-4o et variantes
- S√©rie GPT-4.1
- S√©ries O1, O3, O4

### Variables d'environnement

* `OPENAI_API_KEY` ‚Äì Cl√© OpenAI (optionnel)
* `LOCALAPPDATA`  ‚Äì Red√©finit le r√©pertoire de donn√©es sous Windows

### Arborescence

```
main.py                  # Application principale
config.py                # Configuration
ollama_client.py         # Client API Ollama
chat_window.py           # Fen√™tre principale
models.py                # Dataclasses Message & ModelCaps
utils.py                 # Utilitaires (log, v√©rifications, etc.)
file_utils.py            # Utilitaires de traitement de fichiers (images, PDFs, OCR)
requirements.txt         # D√©pendances
%APPDATA%/OllamaChats/   # Conversations et param√®tres sauvegard√©s
  ‚îú‚îÄ‚îÄ model_favorites.json
  ‚îú‚îÄ‚îÄ model_visibility.json
  ‚îî‚îÄ‚îÄ <uuid>.json        # Une conversation par fichier
```

### Utilisation

1. **D√©marrer une conversation** : Cliquez sur "‚ûï Nouvelle conversation"
2. **Joindre des fichiers** : 
   - Cliquez sur le bouton üìé ou glissez-d√©posez des fichiers
   - Support√©s : Images (analys√©es par les mod√®les de vision), PDFs (texte extrait), fichiers texte
3. **Changer de mod√®le** : Utilisez la liste d√©roulante et le bouton ‚öôÔ∏è pour g√©rer la visibilit√©
4. **Voir la r√©flexion** : Cliquez sur les fl√®ches ‚ñ∂ pour d√©velopper le raisonnement de l'IA
5. **Copier le code** : Cliquez sur le bouton üìÑ sur les blocs de code

### Cr√©ation d'un ex√©cutable Windows

```bash
pip install pyinstaller
pyinstaller --onefile --noconsole main.py
```

### Contribuer

Les pull requests et issues sont les bienvenus !

### Licence

MIT
